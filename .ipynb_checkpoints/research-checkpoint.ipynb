{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f29d71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-24 15:22:36.503583: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from tensorflow import keras\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set custom styles for text color\n",
    "plt.rcParams['text.color'] = 'white'\n",
    "plt.rcParams['axes.labelcolor'] = 'white'\n",
    "plt.rcParams['axes.titlecolor'] = 'white'\n",
    "plt.rcParams['xtick.color'] = 'white'  # Color of the x-axis tick values\n",
    "plt.rcParams['ytick.color'] = 'white'  # Color of the y-axis tick values\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2cbea49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53df2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392bab8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nelly Carsoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Peckers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sabih Unhearfus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Meratz Caltilter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brence Harperez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n",
       "1     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n",
       "2     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n",
       "3     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n",
       "4     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
       "0          0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n",
       "1          0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n",
       "2          0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n",
       "3          0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n",
       "4         10.0        0.0         635.0     0.0     0.0   Brence Harperez  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3501c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4277 entries, 0 to 4276\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   4277 non-null   object \n",
      " 1   HomePlanet    4190 non-null   object \n",
      " 2   CryoSleep     4184 non-null   object \n",
      " 3   Cabin         4177 non-null   object \n",
      " 4   Destination   4185 non-null   object \n",
      " 5   Age           4186 non-null   float64\n",
      " 6   VIP           4184 non-null   object \n",
      " 7   RoomService   4195 non-null   float64\n",
      " 8   FoodCourt     4171 non-null   float64\n",
      " 9   ShoppingMall  4179 non-null   float64\n",
      " 10  Spa           4176 non-null   float64\n",
      " 11  VRDeck        4197 non-null   float64\n",
      " 12  Name          4183 non-null   object \n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 434.5+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afdbbc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01        False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c6644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4277 entries, 0 to 4276\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   PassengerId  4277 non-null   object\n",
      " 1   Transported  4277 non-null   bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 37.7+ KB\n"
     ]
    }
   ],
   "source": [
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752674af",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train.columns.to_list()[-1]\n",
    "# convert target from bool to int\n",
    "train[target] = train[target].astype(int)\n",
    "train_target = train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac10a641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(data = train, x = target, color='g')\n",
    "plt.title('Class distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc5d2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(target, axis=1, inplace=True)\n",
    "train_id = train['PassengerId']\n",
    "test_id = test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0dc3007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine over rows, keeping id for now as group number might be useful\n",
    "combined = pd.concat([train, test], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c944f8",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "681e26d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12970 entries, 0 to 4276\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   12970 non-null  object \n",
      " 1   HomePlanet    12682 non-null  object \n",
      " 2   CryoSleep     12660 non-null  object \n",
      " 3   Cabin         12671 non-null  object \n",
      " 4   Destination   12696 non-null  object \n",
      " 5   Age           12700 non-null  float64\n",
      " 6   VIP           12674 non-null  object \n",
      " 7   RoomService   12707 non-null  float64\n",
      " 8   FoodCourt     12681 non-null  float64\n",
      " 9   ShoppingMall  12664 non-null  float64\n",
      " 10  Spa           12686 non-null  float64\n",
      " 11  VRDeck        12702 non-null  float64\n",
      " 12  Name          12676 non-null  object \n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7ca193d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy  \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines  \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent  \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent  \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "201c9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Group'] = combined['PassengerId'].str[:4]\n",
    "combined.drop('PassengerId', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129eb55b",
   "metadata": {},
   "source": [
    "Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9c16245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns\n",
    "col_cat_NA = ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP']\n",
    "\n",
    "# fill with Group first\n",
    "for col in col_cat_NA:\n",
    "    combined[col] = combined.groupby('Group')[col].transform(\n",
    "    lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "    \n",
    "# need to do this, so we can use homeplanet to fill values for destination\n",
    "combined['HomePlanet'].fillna('', inplace=True)\n",
    "combined['Destination'] = combined.groupby('HomePlanet')['Destination'].transform(\n",
    "    lambda x: x.fillna(x.mode()[0]))\n",
    "# reverse what we did earlier\n",
    "combined['HomePlanet'].replace('', np.nan, inplace=True)\n",
    "\n",
    "# now fill homeplanet with destination\n",
    "combined['HomePlanet'] = combined.groupby('Destination')['HomePlanet'].transform(\n",
    "    lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "combined['CryoSleep'] = combined.groupby('Destination')['CryoSleep'].transform(\n",
    "    lambda x: x.fillna(x.mode()[0]))\n",
    "combined['VIP'].fillna(False, inplace=True)\n",
    "    \n",
    "# need to break cabin down, this is screwing it up when the entire cabin isn't available\n",
    "combined[['deck', 'cabin_num', 'side']] = combined['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "combined.drop('Cabin', inplace=True, axis=1)\n",
    "\n",
    "col_cat_na = ['deck', 'cabin_num', 'side']\n",
    "\n",
    "for col in col_cat_na:\n",
    "    combined[col] = combined.groupby('Destination')[col].transform(\n",
    "        lambda x: x.fillna(x.mode()[0]))\n",
    "combined['cabin_num'] = combined['cabin_num'].astype(int)\n",
    "\n",
    "# drop name\n",
    "combined.drop('Name', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0390b12b",
   "metadata": {},
   "source": [
    "Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6c4e3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# numerical columns \n",
    "col_num = combined.select_dtypes(include=['number']).columns\n",
    "col_num = col_num.drop(['cabin_num', 'CryoSleep'])\n",
    "\n",
    "# subplot placehodlers\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12,8))\n",
    "\n",
    "# flatten the axes for easier indexing\n",
    "axes = axes.ravel()\n",
    "\n",
    "# iterate over number columns, enumerate cause working with index list\n",
    "for i, col in enumerate(col_num):\n",
    "    ax = axes[i]\n",
    "    # checking distribution for data above 0\n",
    "    t = combined.loc[combined[col]>0]\n",
    "    sns.histplot(t[col], ax=ax, kde=True, bins=100)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "# adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a46455c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>cabin_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4404.000000</td>\n",
       "      <td>4321.000000</td>\n",
       "      <td>4404.000000</td>\n",
       "      <td>4296.000000</td>\n",
       "      <td>4303.000000</td>\n",
       "      <td>4304.000000</td>\n",
       "      <td>4322.000000</td>\n",
       "      <td>4404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004087</td>\n",
       "      <td>31.032631</td>\n",
       "      <td>643.134196</td>\n",
       "      <td>484.818203</td>\n",
       "      <td>313.019986</td>\n",
       "      <td>365.609433</td>\n",
       "      <td>337.559695</td>\n",
       "      <td>645.533606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.063808</td>\n",
       "      <td>12.431650</td>\n",
       "      <td>969.486624</td>\n",
       "      <td>1477.621759</td>\n",
       "      <td>657.312688</td>\n",
       "      <td>1118.498526</td>\n",
       "      <td>1187.149866</td>\n",
       "      <td>536.059777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>193.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>313.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>471.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>1070.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>14327.000000</td>\n",
       "      <td>26830.000000</td>\n",
       "      <td>8098.000000</td>\n",
       "      <td>22408.000000</td>\n",
       "      <td>24133.000000</td>\n",
       "      <td>1894.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CryoSleep          Age   RoomService     FoodCourt  ShoppingMall  \\\n",
       "count  4404.000000  4321.000000   4404.000000   4296.000000   4303.000000   \n",
       "mean      0.004087    31.032631    643.134196    484.818203    313.019986   \n",
       "std       0.063808    12.431650    969.486624   1477.621759    657.312688   \n",
       "min       0.000000    13.000000      1.000000      0.000000      0.000000   \n",
       "25%       0.000000    21.000000     37.000000      0.000000      0.000000   \n",
       "50%       0.000000    28.000000    313.500000      2.000000     19.000000   \n",
       "75%       0.000000    38.000000    857.000000    276.000000    372.000000   \n",
       "max       1.000000    79.000000  14327.000000  26830.000000   8098.000000   \n",
       "\n",
       "                Spa        VRDeck    cabin_num  \n",
       "count   4304.000000   4322.000000  4404.000000  \n",
       "mean     365.609433    337.559695   645.533606  \n",
       "std     1118.498526   1187.149866   536.059777  \n",
       "min        0.000000      0.000000     0.000000  \n",
       "25%        0.000000      0.000000   193.000000  \n",
       "50%        6.000000      1.000000   471.000000  \n",
       "75%      245.000000    171.000000  1070.250000  \n",
       "max    22408.000000  24133.000000  1894.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3s/l2m1db5135751grhtk16_j200000gn/T/ipykernel_20543/3600371989.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  display(combined.loc[combined['RoomService']>0].median())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CryoSleep          0.0\n",
       "Age               28.0\n",
       "VIP                0.0\n",
       "RoomService      313.5\n",
       "FoodCourt          2.0\n",
       "ShoppingMall      19.0\n",
       "Spa                6.0\n",
       "VRDeck             1.0\n",
       "Group           4639.5\n",
       "cabin_num        471.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(combined.loc[combined['RoomService']>0].describe())\n",
    "display(combined.loc[combined['RoomService']>0].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99926cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 0s with null\n",
    "combined[col_num] = combined[col_num].replace(0, np.nan)\n",
    "\n",
    "# fill with Group first\n",
    "for i, col in enumerate(col_num):\n",
    "    combined[col] = combined.groupby('Group')[col].transform(\n",
    "        lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc579183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with destination now\n",
    "for i, col in enumerate(col_num):\n",
    "    combined[col] = combined.groupby('Destination')[col].transform(\n",
    "        lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6974291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take log due to skewed distribution\n",
    "for i, col in enumerate(col_num):\n",
    "    combined[col] = np.log1p(combined[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63f1cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new features\n",
    "combined['TotalSpent'] = combined[['RoomService', 'FoodCourt', \n",
    "                                   'ShoppingMall','Spa', 'VRDeck']].sum(axis=1)\n",
    "\n",
    "# since the distribution is so skewed to 0s, this might help\n",
    "# combined['moneySpent'] = (combined['TotalSpent']>0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2fa1aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 1.0], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['VIP'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8913d33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "col = 'TotalSpent'\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(data=combined, x=col, color='g', kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b84751ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_bool = ['CryoSleep', 'VIP']\n",
    "\n",
    "# correct dtypes of boolean columns from object to bool then to int\n",
    "for col in col_bool:\n",
    "    combined[col] = combined[col].astype(bool).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "967f5469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12970 entries, 0 to 4276\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   HomePlanet    12970 non-null  object \n",
      " 1   CryoSleep     12970 non-null  int64  \n",
      " 2   Destination   12970 non-null  object \n",
      " 3   Age           12970 non-null  float64\n",
      " 4   VIP           12970 non-null  int64  \n",
      " 5   RoomService   12970 non-null  float64\n",
      " 6   FoodCourt     12970 non-null  float64\n",
      " 7   ShoppingMall  12970 non-null  float64\n",
      " 8   Spa           12970 non-null  float64\n",
      " 9   VRDeck        12970 non-null  float64\n",
      " 10  Group         12970 non-null  object \n",
      " 11  deck          12970 non-null  object \n",
      " 12  cabin_num     12970 non-null  int64  \n",
      " 13  side          12970 non-null  object \n",
      " 14  TotalSpent    12970 non-null  float64\n",
      "dtypes: float64(7), int64(3), object(5)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# convert category columns to numerical/binary\n",
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58df1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "combined = pd.get_dummies(combined, columns=['HomePlanet', 'Destination', 'deck', 'side'])\n",
    "\n",
    "# shouldn't be, but for now, let's...maybe this does make sense after all\n",
    "combined['Group'] = combined['Group'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14f81999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dtypes to int\n",
    "combined.iloc[:, -16:] = combined.iloc[:, -16:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adfdd8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12970 entries, 0 to 4276\n",
      "Data columns (total 27 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   CryoSleep                  12970 non-null  int64  \n",
      " 1   Age                        12970 non-null  float64\n",
      " 2   VIP                        12970 non-null  int64  \n",
      " 3   RoomService                12970 non-null  float64\n",
      " 4   FoodCourt                  12970 non-null  float64\n",
      " 5   ShoppingMall               12970 non-null  float64\n",
      " 6   Spa                        12970 non-null  float64\n",
      " 7   VRDeck                     12970 non-null  float64\n",
      " 8   Group                      12970 non-null  int64  \n",
      " 9   cabin_num                  12970 non-null  int64  \n",
      " 10  TotalSpent                 12970 non-null  float64\n",
      " 11  HomePlanet_Earth           12970 non-null  int64  \n",
      " 12  HomePlanet_Europa          12970 non-null  int64  \n",
      " 13  HomePlanet_Mars            12970 non-null  int64  \n",
      " 14  Destination_55 Cancri e    12970 non-null  int64  \n",
      " 15  Destination_PSO J318.5-22  12970 non-null  int64  \n",
      " 16  Destination_TRAPPIST-1e    12970 non-null  int64  \n",
      " 17  deck_A                     12970 non-null  int64  \n",
      " 18  deck_B                     12970 non-null  int64  \n",
      " 19  deck_C                     12970 non-null  int64  \n",
      " 20  deck_D                     12970 non-null  int64  \n",
      " 21  deck_E                     12970 non-null  int64  \n",
      " 22  deck_F                     12970 non-null  int64  \n",
      " 23  deck_G                     12970 non-null  int64  \n",
      " 24  deck_T                     12970 non-null  int64  \n",
      " 25  side_P                     12970 non-null  int64  \n",
      " 26  side_S                     12970 non-null  int64  \n",
      "dtypes: float64(7), int64(20)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c6bf8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving a combined copy\n",
    "combinedCopy = combined.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63673e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combinedCopy.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765aaf89",
   "metadata": {},
   "source": [
    "Min-max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33671796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_norm(col):\n",
    "    min_val = col.min()\n",
    "    max_val = col.max()\n",
    "    \n",
    "    return (col-min_val) / (max_val - min_val)\n",
    "\n",
    "combined = combined.apply(min_max_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019d3909",
   "metadata": {},
   "source": [
    "### Model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e284b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (8693, 28)\n",
      "Test shape (4277, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3s/l2m1db5135751grhtk16_j200000gn/T/ipykernel_20543/2658725243.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[target] = train_target\n"
     ]
    }
   ],
   "source": [
    "train = combined.iloc[:train_id.shape[0]]\n",
    "test = combined.iloc[-test_id.shape[0]:]\n",
    "train[target] = train_target\n",
    "print('Train shape', train.shape)\n",
    "print('Test shape', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80e88cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6075 samples in training, 2618 samples in testing data\n"
     ]
    }
   ],
   "source": [
    "# let's split train data into train/test\n",
    "def train_test_split(data, test_ratio=0.3):\n",
    "    test_indices = np.random.rand(data.shape[0]) < test_ratio\n",
    "    return data[~test_indices], data[test_indices]\n",
    "train_data, test_data = train_test_split(train)\n",
    "print('{} samples in training, {} samples in testing data'.format(train_data.shape[0], \n",
    "                                                            test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65624cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Group</th>\n",
       "      <th>cabin_num</th>\n",
       "      <th>TotalSpent</th>\n",
       "      <th>HomePlanet_Earth</th>\n",
       "      <th>HomePlanet_Europa</th>\n",
       "      <th>HomePlanet_Mars</th>\n",
       "      <th>Destination_55 Cancri e</th>\n",
       "      <th>Destination_PSO J318.5-22</th>\n",
       "      <th>Destination_TRAPPIST-1e</th>\n",
       "      <th>deck_A</th>\n",
       "      <th>deck_B</th>\n",
       "      <th>deck_C</th>\n",
       "      <th>deck_D</th>\n",
       "      <th>deck_E</th>\n",
       "      <th>deck_F</th>\n",
       "      <th>deck_G</th>\n",
       "      <th>deck_T</th>\n",
       "      <th>side_P</th>\n",
       "      <th>side_S</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451438</td>\n",
       "      <td>0.167483</td>\n",
       "      <td>0.273702</td>\n",
       "      <td>0.602395</td>\n",
       "      <td>0.331287</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.348215</td>\n",
       "      <td>0.779340</td>\n",
       "      <td>0.557632</td>\n",
       "      <td>0.870768</td>\n",
       "      <td>0.342498</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.643357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.768042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348215</td>\n",
       "      <td>0.672723</td>\n",
       "      <td>0.557632</td>\n",
       "      <td>0.795530</td>\n",
       "      <td>0.486763</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.844027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515354</td>\n",
       "      <td>0.571194</td>\n",
       "      <td>0.490608</td>\n",
       "      <td>0.534488</td>\n",
       "      <td>0.513321</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345625</td>\n",
       "      <td>0.691642</td>\n",
       "      <td>0.073965</td>\n",
       "      <td>0.514345</td>\n",
       "      <td>0.505796</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.385912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8687</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.743001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768042</td>\n",
       "      <td>0.501582</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.543610</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>0.051214</td>\n",
       "      <td>0.301321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.610292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515354</td>\n",
       "      <td>0.452702</td>\n",
       "      <td>0.490608</td>\n",
       "      <td>0.433614</td>\n",
       "      <td>0.513321</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.791447</td>\n",
       "      <td>0.473066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.590200</td>\n",
       "      <td>0.539814</td>\n",
       "      <td>0.730117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505796</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.791975</td>\n",
       "      <td>0.459892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.759949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467627</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>0.461422</td>\n",
       "      <td>0.555138</td>\n",
       "      <td>0.786206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.321014</td>\n",
       "      <td>0.649080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.844027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467627</td>\n",
       "      <td>0.807509</td>\n",
       "      <td>0.501582</td>\n",
       "      <td>0.555138</td>\n",
       "      <td>0.199165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.321014</td>\n",
       "      <td>0.518534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6075 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CryoSleep       Age  VIP  RoomService  FoodCourt  ShoppingMall  \\\n",
       "1           0.0  0.684687  0.0     0.451438   0.167483      0.273702   \n",
       "2           0.0  0.917458  1.0     0.348215   0.779340      0.557632   \n",
       "3           0.0  0.768042  0.0     0.348215   0.672723      0.557632   \n",
       "5           0.0  0.844027  0.0     0.515354   0.571194      0.490608   \n",
       "6           0.0  0.705550  0.0     0.345625   0.691642      0.073965   \n",
       "...         ...       ...  ...          ...        ...           ...   \n",
       "8687        0.0  0.743001  0.0     0.000000   0.768042      0.501582   \n",
       "8689        1.0  0.610292  0.0     0.515354   0.452702      0.490608   \n",
       "8690        0.0  0.705550  0.0     0.590200   0.539814      0.730117   \n",
       "8691        0.0  0.759949  0.0     0.467627   0.651786      0.461422   \n",
       "8692        0.0  0.844027  0.0     0.467627   0.807509      0.501582   \n",
       "\n",
       "           Spa    VRDeck     Group  cabin_num  TotalSpent  HomePlanet_Earth  \\\n",
       "1     0.602395  0.331287  0.000108   0.000000    0.276838               1.0   \n",
       "2     0.870768  0.342498  0.000216   0.000000    0.643357               0.0   \n",
       "3     0.795530  0.486763  0.000216   0.000000    0.630095               0.0   \n",
       "5     0.534488  0.513321  0.000431   0.000000    0.547546               1.0   \n",
       "6     0.514345  0.505796  0.000539   0.001056    0.385912               1.0   \n",
       "...        ...       ...       ...        ...         ...               ...   \n",
       "8687  0.043486  0.543610  0.999461   0.051214    0.301321               0.0   \n",
       "8689  0.433614  0.513321  0.999784   0.791447    0.473066               1.0   \n",
       "8690  0.000000  0.505796  0.999892   0.791975    0.459892               1.0   \n",
       "8691  0.555138  0.786206  1.000000   0.321014    0.649080               0.0   \n",
       "8692  0.555138  0.199165  1.000000   0.321014    0.518534               0.0   \n",
       "\n",
       "      HomePlanet_Europa  HomePlanet_Mars  Destination_55 Cancri e  \\\n",
       "1                   0.0              0.0                      0.0   \n",
       "2                   1.0              0.0                      0.0   \n",
       "3                   1.0              0.0                      0.0   \n",
       "5                   0.0              0.0                      0.0   \n",
       "6                   0.0              0.0                      0.0   \n",
       "...                 ...              ...                      ...   \n",
       "8687                1.0              0.0                      0.0   \n",
       "8689                0.0              0.0                      0.0   \n",
       "8690                0.0              0.0                      0.0   \n",
       "8691                1.0              0.0                      1.0   \n",
       "8692                1.0              0.0                      0.0   \n",
       "\n",
       "      Destination_PSO J318.5-22  Destination_TRAPPIST-1e  deck_A  deck_B  \\\n",
       "1                           0.0                      1.0     0.0     0.0   \n",
       "2                           0.0                      1.0     1.0     0.0   \n",
       "3                           0.0                      1.0     1.0     0.0   \n",
       "5                           1.0                      0.0     0.0     0.0   \n",
       "6                           0.0                      1.0     0.0     0.0   \n",
       "...                         ...                      ...     ...     ...   \n",
       "8687                        0.0                      1.0     1.0     0.0   \n",
       "8689                        1.0                      0.0     0.0     0.0   \n",
       "8690                        0.0                      1.0     0.0     0.0   \n",
       "8691                        0.0                      0.0     0.0     0.0   \n",
       "8692                        0.0                      1.0     0.0     0.0   \n",
       "\n",
       "      deck_C  deck_D  deck_E  deck_F  deck_G  deck_T  side_P  side_S  \\\n",
       "1        0.0     0.0     0.0     1.0     0.0     0.0     0.0     1.0   \n",
       "2        0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "3        0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "5        0.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0   \n",
       "6        0.0     0.0     0.0     1.0     0.0     0.0     0.0     1.0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "8687     0.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "8689     0.0     0.0     0.0     0.0     1.0     0.0     0.0     1.0   \n",
       "8690     0.0     0.0     0.0     0.0     1.0     0.0     0.0     1.0   \n",
       "8691     0.0     0.0     1.0     0.0     0.0     0.0     0.0     1.0   \n",
       "8692     0.0     0.0     1.0     0.0     0.0     0.0     0.0     1.0   \n",
       "\n",
       "      Transported  \n",
       "1               1  \n",
       "2               0  \n",
       "3               0  \n",
       "5               1  \n",
       "6               1  \n",
       "...           ...  \n",
       "8687            1  \n",
       "8689            0  \n",
       "8690            1  \n",
       "8691            0  \n",
       "8692            1  \n",
       "\n",
       "[6075 rows x 28 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d10c029",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6075 entries, 1 to 8692\n",
      "Data columns (total 28 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   CryoSleep                  6075 non-null   float64\n",
      " 1   Age                        6075 non-null   float64\n",
      " 2   VIP                        6075 non-null   float64\n",
      " 3   RoomService                6075 non-null   float64\n",
      " 4   FoodCourt                  6075 non-null   float64\n",
      " 5   ShoppingMall               6075 non-null   float64\n",
      " 6   Spa                        6075 non-null   float64\n",
      " 7   VRDeck                     6075 non-null   float64\n",
      " 8   Group                      6075 non-null   float64\n",
      " 9   cabin_num                  6075 non-null   float64\n",
      " 10  TotalSpent                 6075 non-null   float64\n",
      " 11  HomePlanet_Earth           6075 non-null   float64\n",
      " 12  HomePlanet_Europa          6075 non-null   float64\n",
      " 13  HomePlanet_Mars            6075 non-null   float64\n",
      " 14  Destination_55 Cancri e    6075 non-null   float64\n",
      " 15  Destination_PSO J318.5-22  6075 non-null   float64\n",
      " 16  Destination_TRAPPIST-1e    6075 non-null   float64\n",
      " 17  deck_A                     6075 non-null   float64\n",
      " 18  deck_B                     6075 non-null   float64\n",
      " 19  deck_C                     6075 non-null   float64\n",
      " 20  deck_D                     6075 non-null   float64\n",
      " 21  deck_E                     6075 non-null   float64\n",
      " 22  deck_F                     6075 non-null   float64\n",
      " 23  deck_G                     6075 non-null   float64\n",
      " 24  deck_T                     6075 non-null   float64\n",
      " 25  side_P                     6075 non-null   float64\n",
      " 26  side_S                     6075 non-null   float64\n",
      " 27  Transported                6075 non-null   int64  \n",
      "dtypes: float64(27), int64(1)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff5f4b3",
   "metadata": {},
   "source": [
    "Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51507c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=10000)\n",
    "lr.fit(train_data.iloc[:, :-1], train_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8baf1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lr.predict(test_data.iloc[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf772c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_data[target], prediction)\n",
    "print('Accuracy of {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86beb750",
   "metadata": {},
   "source": [
    "Model: SVM (takes a while to run this though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10], # regularization parameter\n",
    "#     'kernel': ['linear', 'rbf'], # kernel type\n",
    "#     'gamma': [0.1, 1, 10] # kernel coefficient\n",
    "# }\n",
    "\n",
    "# svm = SVC()\n",
    "# grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "# grid_search.fit(train_data.iloc[:, :-1], train_data[target])\n",
    "\n",
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f3977c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60301781",
   "metadata": {},
   "source": [
    "Model: TFDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2396a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert these to tensorflow datasets\n",
    "train_data = tfdf.keras.pd_dataframe_to_tf_dataset(train_data, label=target)\n",
    "test_data = tfdf.keras.pd_dataframe_to_tf_dataset(test_data, label=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc88f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = tfdf.keras.RandomForestModel()\n",
    "rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee19947",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0754d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.compile(metrics=['accuracy'])\n",
    "evaluation = rf.evaluate(test_data, return_dict=True)\n",
    "display(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ae7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfdf.model_plotter.plot_model_in_colab(rf, tree_idx=0, max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d2277",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec88fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tfdf.keras.pd_dataframe_to_tf_dataset(test)\n",
    "predictions = rf.predict(test)\n",
    "output = pd.DataFrame({'PassengerId': test_id, 'Transported': predictions.squeeze()})\n",
    "# convert to boolean\n",
    "output[target] = (output[target] >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf32efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c985a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('data/sample_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1895d310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a7b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b81eca8",
   "metadata": {},
   "source": [
    "Model : FNN  \n",
    "Feedforwrad Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb54d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can optimize following two\n",
    "layer_size = 8\n",
    "neuron_size = 64\n",
    "\n",
    "layer_activation = 'relu'\n",
    "output_activation = 'sigmoid'\n",
    "\n",
    "# based on data\n",
    "feature_size = train_data.shape[1]-1 # -1 cause target column\n",
    "target_class_count = len(train_data[target].unique())-1 # cause binary, 0 doesn't count\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(layer_size, activation=layer_activation, \n",
    "                      input_shape=(feature_size,)),\n",
    "    keras.layers.Dense(neuron_size, activation=layer_activation),\n",
    "    keras.layers.Dense(target_class_count, activation=output_activation)\n",
    "])\n",
    "\n",
    "# optimizer options: SGD, Adam, RMSprop, Adagrad, Adadelta, Nadam, Ftrl\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ee05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.5009 - val_loss: 0.6946 - val_accuracy: 0.5149\n",
      "Epoch 2/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5218 - val_loss: 0.6896 - val_accuracy: 0.5413\n",
      "Epoch 3/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5470 - val_loss: 0.6861 - val_accuracy: 0.5649\n",
      "Epoch 4/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.5751 - val_loss: 0.6832 - val_accuracy: 0.5924\n",
      "Epoch 5/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5891 - val_loss: 0.6806 - val_accuracy: 0.5970\n",
      "Epoch 6/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5980 - val_loss: 0.6781 - val_accuracy: 0.6058\n",
      "Epoch 7/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6779 - accuracy: 0.6076 - val_loss: 0.6756 - val_accuracy: 0.6138\n",
      "Epoch 8/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.6178 - val_loss: 0.6729 - val_accuracy: 0.6226\n",
      "Epoch 9/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.6252 - val_loss: 0.6703 - val_accuracy: 0.6299\n",
      "Epoch 10/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.6703 - accuracy: 0.6301 - val_loss: 0.6675 - val_accuracy: 0.6371\n",
      "Epoch 11/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.6357 - val_loss: 0.6645 - val_accuracy: 0.6455\n",
      "Epoch 12/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.6403 - val_loss: 0.6613 - val_accuracy: 0.6478\n",
      "Epoch 13/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.6435 - val_loss: 0.6581 - val_accuracy: 0.6532\n",
      "Epoch 14/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6476 - val_loss: 0.6545 - val_accuracy: 0.6574\n",
      "Epoch 15/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6519 - val_loss: 0.6508 - val_accuracy: 0.6600\n",
      "Epoch 16/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6560 - val_loss: 0.6470 - val_accuracy: 0.6639\n",
      "Epoch 17/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.6601 - val_loss: 0.6429 - val_accuracy: 0.6688\n",
      "Epoch 18/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.6657 - val_loss: 0.6387 - val_accuracy: 0.6738\n",
      "Epoch 19/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.6691 - val_loss: 0.6342 - val_accuracy: 0.6780\n",
      "Epoch 20/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.6723 - val_loss: 0.6295 - val_accuracy: 0.6811\n",
      "Epoch 21/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6752 - val_loss: 0.6246 - val_accuracy: 0.6799\n",
      "Epoch 22/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.6795 - val_loss: 0.6198 - val_accuracy: 0.6803\n",
      "Epoch 23/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6838 - val_loss: 0.6150 - val_accuracy: 0.6837\n",
      "Epoch 24/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6854 - val_loss: 0.6104 - val_accuracy: 0.6853\n",
      "Epoch 25/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.6874 - val_loss: 0.6060 - val_accuracy: 0.6875\n",
      "Epoch 26/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6900 - val_loss: 0.6017 - val_accuracy: 0.6895\n",
      "Epoch 27/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6910 - val_loss: 0.5978 - val_accuracy: 0.6940\n",
      "Epoch 28/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.6935 - val_loss: 0.5939 - val_accuracy: 0.6963\n",
      "Epoch 29/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.6971 - val_loss: 0.5904 - val_accuracy: 0.6975\n",
      "Epoch 30/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6989 - val_loss: 0.5869 - val_accuracy: 0.6990\n",
      "Epoch 31/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.7009 - val_loss: 0.5837 - val_accuracy: 0.6998\n",
      "Epoch 32/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7022 - val_loss: 0.5807 - val_accuracy: 0.7013\n",
      "Epoch 33/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7034 - val_loss: 0.5779 - val_accuracy: 0.6994\n",
      "Epoch 34/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7058 - val_loss: 0.5752 - val_accuracy: 0.7021\n",
      "Epoch 35/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.7065 - val_loss: 0.5727 - val_accuracy: 0.7040\n",
      "Epoch 36/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7081 - val_loss: 0.5705 - val_accuracy: 0.7036\n",
      "Epoch 37/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7086 - val_loss: 0.5685 - val_accuracy: 0.7051\n",
      "Epoch 38/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7086 - val_loss: 0.5666 - val_accuracy: 0.7047\n",
      "Epoch 39/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7093 - val_loss: 0.5648 - val_accuracy: 0.7078\n",
      "Epoch 40/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7100 - val_loss: 0.5631 - val_accuracy: 0.7074\n",
      "Epoch 41/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7113 - val_loss: 0.5616 - val_accuracy: 0.7093\n",
      "Epoch 42/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7116 - val_loss: 0.5602 - val_accuracy: 0.7093\n",
      "Epoch 43/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7119 - val_loss: 0.5589 - val_accuracy: 0.7086\n",
      "Epoch 44/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7131 - val_loss: 0.5577 - val_accuracy: 0.7101\n",
      "Epoch 45/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7141 - val_loss: 0.5566 - val_accuracy: 0.7089\n",
      "Epoch 46/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7156 - val_loss: 0.5555 - val_accuracy: 0.7097\n",
      "Epoch 47/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7154 - val_loss: 0.5544 - val_accuracy: 0.7093\n",
      "Epoch 48/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7165 - val_loss: 0.5534 - val_accuracy: 0.7089\n",
      "Epoch 49/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5516 - accuracy: 0.7177 - val_loss: 0.5525 - val_accuracy: 0.7093\n",
      "Epoch 50/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7198 - val_loss: 0.5516 - val_accuracy: 0.7097\n",
      "Epoch 51/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7193 - val_loss: 0.5507 - val_accuracy: 0.7135\n",
      "Epoch 52/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7225 - val_loss: 0.5500 - val_accuracy: 0.7116\n",
      "Epoch 53/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7215 - val_loss: 0.5490 - val_accuracy: 0.7143\n",
      "Epoch 54/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7241 - val_loss: 0.5483 - val_accuracy: 0.7143\n",
      "Epoch 55/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7226 - val_loss: 0.5474 - val_accuracy: 0.7158\n",
      "Epoch 56/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7248 - val_loss: 0.5467 - val_accuracy: 0.7150\n",
      "Epoch 57/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7251 - val_loss: 0.5459 - val_accuracy: 0.7181\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7249 - val_loss: 0.5451 - val_accuracy: 0.7181\n",
      "Epoch 59/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7263 - val_loss: 0.5443 - val_accuracy: 0.7189\n",
      "Epoch 60/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7264 - val_loss: 0.5436 - val_accuracy: 0.7193\n",
      "Epoch 61/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7266 - val_loss: 0.5429 - val_accuracy: 0.7189\n",
      "Epoch 62/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7291 - val_loss: 0.5421 - val_accuracy: 0.7200\n",
      "Epoch 63/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7264 - val_loss: 0.5415 - val_accuracy: 0.7204\n",
      "Epoch 64/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7291 - val_loss: 0.5407 - val_accuracy: 0.7200\n",
      "Epoch 65/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7289 - val_loss: 0.5400 - val_accuracy: 0.7215\n",
      "Epoch 66/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7299 - val_loss: 0.5393 - val_accuracy: 0.7219\n",
      "Epoch 67/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5370 - accuracy: 0.7295 - val_loss: 0.5386 - val_accuracy: 0.7227\n",
      "Epoch 68/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.7307 - val_loss: 0.5379 - val_accuracy: 0.7215\n",
      "Epoch 69/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.7319 - val_loss: 0.5373 - val_accuracy: 0.7242\n",
      "Epoch 70/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5349 - accuracy: 0.7295 - val_loss: 0.5366 - val_accuracy: 0.7235\n",
      "Epoch 71/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7319 - val_loss: 0.5360 - val_accuracy: 0.7231\n",
      "Epoch 72/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7315 - val_loss: 0.5353 - val_accuracy: 0.7246\n",
      "Epoch 73/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7330 - val_loss: 0.5347 - val_accuracy: 0.7254\n",
      "Epoch 74/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7330 - val_loss: 0.5341 - val_accuracy: 0.7257\n",
      "Epoch 75/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7332 - val_loss: 0.5335 - val_accuracy: 0.7273\n",
      "Epoch 76/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7335 - val_loss: 0.5329 - val_accuracy: 0.7265\n",
      "Epoch 77/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7340 - val_loss: 0.5323 - val_accuracy: 0.7273\n",
      "Epoch 78/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.7340 - val_loss: 0.5317 - val_accuracy: 0.7292\n",
      "Epoch 79/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7338 - val_loss: 0.5311 - val_accuracy: 0.7277\n",
      "Epoch 80/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7358 - val_loss: 0.5306 - val_accuracy: 0.7277\n",
      "Epoch 81/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7343 - val_loss: 0.5301 - val_accuracy: 0.7288\n",
      "Epoch 82/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7351 - val_loss: 0.5295 - val_accuracy: 0.7292\n",
      "Epoch 83/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7361 - val_loss: 0.5290 - val_accuracy: 0.7299\n",
      "Epoch 84/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7366 - val_loss: 0.5285 - val_accuracy: 0.7311\n",
      "Epoch 85/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7351 - val_loss: 0.5280 - val_accuracy: 0.7311\n",
      "Epoch 86/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7363 - val_loss: 0.5275 - val_accuracy: 0.7315\n",
      "Epoch 87/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5246 - accuracy: 0.7379 - val_loss: 0.5270 - val_accuracy: 0.7322\n",
      "Epoch 88/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7376 - val_loss: 0.5265 - val_accuracy: 0.7319\n",
      "Epoch 89/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7386 - val_loss: 0.5260 - val_accuracy: 0.7319\n",
      "Epoch 90/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7373 - val_loss: 0.5255 - val_accuracy: 0.7326\n",
      "Epoch 91/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7379 - val_loss: 0.5250 - val_accuracy: 0.7322\n",
      "Epoch 92/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7388 - val_loss: 0.5245 - val_accuracy: 0.7338\n",
      "Epoch 93/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7384 - val_loss: 0.5241 - val_accuracy: 0.7326\n",
      "Epoch 94/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7378 - val_loss: 0.5236 - val_accuracy: 0.7341\n",
      "Epoch 95/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7384 - val_loss: 0.5231 - val_accuracy: 0.7345\n",
      "Epoch 96/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7383 - val_loss: 0.5227 - val_accuracy: 0.7353\n",
      "Epoch 97/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7391 - val_loss: 0.5222 - val_accuracy: 0.7349\n",
      "Epoch 98/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7399 - val_loss: 0.5218 - val_accuracy: 0.7361\n",
      "Epoch 99/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7386 - val_loss: 0.5213 - val_accuracy: 0.7361\n",
      "Epoch 100/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7404 - val_loss: 0.5209 - val_accuracy: 0.7368\n",
      "Epoch 101/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7399 - val_loss: 0.5204 - val_accuracy: 0.7361\n",
      "Epoch 102/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7404 - val_loss: 0.5200 - val_accuracy: 0.7364\n",
      "Epoch 103/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7402 - val_loss: 0.5195 - val_accuracy: 0.7376\n",
      "Epoch 104/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7404 - val_loss: 0.5191 - val_accuracy: 0.7380\n",
      "Epoch 105/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7411 - val_loss: 0.5187 - val_accuracy: 0.7380\n",
      "Epoch 106/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7412 - val_loss: 0.5184 - val_accuracy: 0.7372\n",
      "Epoch 107/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7409 - val_loss: 0.5179 - val_accuracy: 0.7387\n",
      "Epoch 108/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7419 - val_loss: 0.5175 - val_accuracy: 0.7391\n",
      "Epoch 109/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7419 - val_loss: 0.5170 - val_accuracy: 0.7391\n",
      "Epoch 110/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7430 - val_loss: 0.5168 - val_accuracy: 0.7383\n",
      "Epoch 111/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7435 - val_loss: 0.5166 - val_accuracy: 0.7376\n",
      "Epoch 112/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7429 - val_loss: 0.5160 - val_accuracy: 0.7387\n",
      "Epoch 113/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7437 - val_loss: 0.5155 - val_accuracy: 0.7391\n",
      "Epoch 114/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7445 - val_loss: 0.5151 - val_accuracy: 0.7387\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7435 - val_loss: 0.5148 - val_accuracy: 0.7383\n",
      "Epoch 116/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7439 - val_loss: 0.5146 - val_accuracy: 0.7376\n",
      "Epoch 117/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7439 - val_loss: 0.5140 - val_accuracy: 0.7391\n",
      "Epoch 118/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7439 - val_loss: 0.5138 - val_accuracy: 0.7372\n",
      "Epoch 119/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7430 - val_loss: 0.5133 - val_accuracy: 0.7395\n",
      "Epoch 120/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7449 - val_loss: 0.5131 - val_accuracy: 0.7372\n",
      "Epoch 121/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7455 - val_loss: 0.5127 - val_accuracy: 0.7422\n",
      "Epoch 122/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7439 - val_loss: 0.5122 - val_accuracy: 0.7410\n",
      "Epoch 123/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7442 - val_loss: 0.5118 - val_accuracy: 0.7410\n",
      "Epoch 124/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7444 - val_loss: 0.5115 - val_accuracy: 0.7414\n",
      "Epoch 125/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7452 - val_loss: 0.5112 - val_accuracy: 0.7383\n",
      "Epoch 126/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7452 - val_loss: 0.5108 - val_accuracy: 0.7406\n",
      "Epoch 127/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7457 - val_loss: 0.5105 - val_accuracy: 0.7406\n",
      "Epoch 128/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7449 - val_loss: 0.5102 - val_accuracy: 0.7383\n",
      "Epoch 129/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7457 - val_loss: 0.5098 - val_accuracy: 0.7406\n",
      "Epoch 130/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7449 - val_loss: 0.5094 - val_accuracy: 0.7403\n",
      "Epoch 131/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7447 - val_loss: 0.5091 - val_accuracy: 0.7403\n",
      "Epoch 132/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7447 - val_loss: 0.5090 - val_accuracy: 0.7418\n",
      "Epoch 133/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7450 - val_loss: 0.5086 - val_accuracy: 0.7418\n",
      "Epoch 134/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7455 - val_loss: 0.5083 - val_accuracy: 0.7418\n",
      "Epoch 135/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7450 - val_loss: 0.5080 - val_accuracy: 0.7426\n",
      "Epoch 136/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7468 - val_loss: 0.5077 - val_accuracy: 0.7422\n",
      "Epoch 137/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7463 - val_loss: 0.5074 - val_accuracy: 0.7422\n",
      "Epoch 138/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7457 - val_loss: 0.5071 - val_accuracy: 0.7414\n",
      "Epoch 139/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7455 - val_loss: 0.5069 - val_accuracy: 0.7437\n",
      "Epoch 140/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7460 - val_loss: 0.5068 - val_accuracy: 0.7429\n",
      "Epoch 141/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7463 - val_loss: 0.5065 - val_accuracy: 0.7429\n",
      "Epoch 142/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7467 - val_loss: 0.5061 - val_accuracy: 0.7426\n",
      "Epoch 143/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7462 - val_loss: 0.5060 - val_accuracy: 0.7445\n",
      "Epoch 144/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7477 - val_loss: 0.5056 - val_accuracy: 0.7426\n",
      "Epoch 145/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7463 - val_loss: 0.5053 - val_accuracy: 0.7422\n",
      "Epoch 146/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7470 - val_loss: 0.5051 - val_accuracy: 0.7433\n",
      "Epoch 147/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7473 - val_loss: 0.5048 - val_accuracy: 0.7426\n",
      "Epoch 148/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7465 - val_loss: 0.5046 - val_accuracy: 0.7456\n",
      "Epoch 149/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7478 - val_loss: 0.5043 - val_accuracy: 0.7441\n",
      "Epoch 150/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7470 - val_loss: 0.5043 - val_accuracy: 0.7456\n",
      "Epoch 151/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7483 - val_loss: 0.5038 - val_accuracy: 0.7445\n",
      "Epoch 152/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7493 - val_loss: 0.5037 - val_accuracy: 0.7441\n",
      "Epoch 153/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7488 - val_loss: 0.5036 - val_accuracy: 0.7441\n",
      "Epoch 154/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7481 - val_loss: 0.5033 - val_accuracy: 0.7437\n",
      "Epoch 155/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7486 - val_loss: 0.5031 - val_accuracy: 0.7437\n",
      "Epoch 156/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7485 - val_loss: 0.5029 - val_accuracy: 0.7433\n",
      "Epoch 157/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7488 - val_loss: 0.5027 - val_accuracy: 0.7441\n",
      "Epoch 158/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7495 - val_loss: 0.5025 - val_accuracy: 0.7452\n",
      "Epoch 159/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7477 - val_loss: 0.5025 - val_accuracy: 0.7456\n",
      "Epoch 160/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7490 - val_loss: 0.5022 - val_accuracy: 0.7452\n",
      "Epoch 161/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7501 - val_loss: 0.5019 - val_accuracy: 0.7433\n",
      "Epoch 162/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7490 - val_loss: 0.5018 - val_accuracy: 0.7426\n",
      "Epoch 163/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7488 - val_loss: 0.5017 - val_accuracy: 0.7452\n",
      "Epoch 164/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7505 - val_loss: 0.5015 - val_accuracy: 0.7426\n",
      "Epoch 165/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7501 - val_loss: 0.5014 - val_accuracy: 0.7437\n",
      "Epoch 166/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7488 - val_loss: 0.5013 - val_accuracy: 0.7445\n",
      "Epoch 167/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7503 - val_loss: 0.5011 - val_accuracy: 0.7437\n",
      "Epoch 168/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7508 - val_loss: 0.5014 - val_accuracy: 0.7452\n",
      "Epoch 169/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7508 - val_loss: 0.5008 - val_accuracy: 0.7433\n",
      "Epoch 170/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7495 - val_loss: 0.5007 - val_accuracy: 0.7429\n",
      "Epoch 171/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7503 - val_loss: 0.5006 - val_accuracy: 0.7445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7505 - val_loss: 0.5004 - val_accuracy: 0.7426\n",
      "Epoch 173/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7509 - val_loss: 0.5003 - val_accuracy: 0.7426\n",
      "Epoch 174/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7513 - val_loss: 0.5004 - val_accuracy: 0.7448\n",
      "Epoch 175/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7516 - val_loss: 0.5004 - val_accuracy: 0.7445\n",
      "Epoch 176/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7508 - val_loss: 0.4999 - val_accuracy: 0.7441\n",
      "Epoch 177/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7500 - val_loss: 0.5001 - val_accuracy: 0.7456\n",
      "Epoch 178/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7511 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
      "Epoch 179/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7511 - val_loss: 0.4995 - val_accuracy: 0.7433\n",
      "Epoch 180/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7506 - val_loss: 0.4995 - val_accuracy: 0.7441\n",
      "Epoch 181/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7514 - val_loss: 0.4993 - val_accuracy: 0.7422\n",
      "Epoch 182/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7503 - val_loss: 0.4993 - val_accuracy: 0.7437\n",
      "Epoch 183/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7503 - val_loss: 0.4992 - val_accuracy: 0.7441\n",
      "Epoch 184/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7513 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
      "Epoch 185/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7514 - val_loss: 0.4988 - val_accuracy: 0.7426\n",
      "Epoch 186/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7514 - val_loss: 0.4986 - val_accuracy: 0.7418\n",
      "Epoch 187/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7495 - val_loss: 0.4986 - val_accuracy: 0.7441\n",
      "Epoch 188/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7506 - val_loss: 0.4986 - val_accuracy: 0.7426\n",
      "Epoch 189/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7501 - val_loss: 0.4986 - val_accuracy: 0.7437\n",
      "Epoch 190/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7514 - val_loss: 0.4984 - val_accuracy: 0.7433\n",
      "Epoch 191/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7506 - val_loss: 0.4983 - val_accuracy: 0.7445\n",
      "Epoch 192/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7503 - val_loss: 0.4982 - val_accuracy: 0.7441\n",
      "Epoch 193/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7511 - val_loss: 0.4982 - val_accuracy: 0.7445\n",
      "Epoch 194/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7505 - val_loss: 0.4980 - val_accuracy: 0.7433\n",
      "Epoch 195/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7511 - val_loss: 0.4981 - val_accuracy: 0.7448\n",
      "Epoch 196/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7513 - val_loss: 0.4978 - val_accuracy: 0.7437\n",
      "Epoch 197/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7506 - val_loss: 0.4977 - val_accuracy: 0.7452\n",
      "Epoch 198/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7513 - val_loss: 0.4977 - val_accuracy: 0.7433\n",
      "Epoch 199/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7511 - val_loss: 0.4976 - val_accuracy: 0.7452\n",
      "Epoch 200/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7533 - val_loss: 0.4977 - val_accuracy: 0.7452\n",
      "Epoch 201/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7495 - val_loss: 0.4975 - val_accuracy: 0.7429\n",
      "Epoch 202/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7505 - val_loss: 0.4974 - val_accuracy: 0.7445\n",
      "Epoch 203/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7528 - val_loss: 0.4975 - val_accuracy: 0.7445\n",
      "Epoch 204/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7529 - val_loss: 0.4974 - val_accuracy: 0.7433\n",
      "Epoch 205/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7516 - val_loss: 0.4975 - val_accuracy: 0.7433\n",
      "Epoch 206/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7506 - val_loss: 0.4974 - val_accuracy: 0.7445\n",
      "Epoch 207/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7521 - val_loss: 0.4972 - val_accuracy: 0.7429\n",
      "Epoch 208/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7514 - val_loss: 0.4971 - val_accuracy: 0.7441\n",
      "Epoch 209/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7518 - val_loss: 0.4971 - val_accuracy: 0.7441\n",
      "Epoch 210/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7521 - val_loss: 0.4969 - val_accuracy: 0.7433\n",
      "Epoch 211/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7521 - val_loss: 0.4972 - val_accuracy: 0.7460\n",
      "Epoch 212/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7533 - val_loss: 0.4967 - val_accuracy: 0.7429\n",
      "Epoch 213/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7518 - val_loss: 0.4966 - val_accuracy: 0.7452\n",
      "Epoch 214/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7516 - val_loss: 0.4966 - val_accuracy: 0.7437\n",
      "Epoch 215/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7516 - val_loss: 0.4967 - val_accuracy: 0.7464\n",
      "Epoch 216/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7506 - val_loss: 0.4965 - val_accuracy: 0.7456\n",
      "Epoch 217/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7529 - val_loss: 0.4968 - val_accuracy: 0.7468\n",
      "Epoch 218/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7521 - val_loss: 0.4966 - val_accuracy: 0.7460\n",
      "Epoch 219/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7513 - val_loss: 0.4964 - val_accuracy: 0.7452\n",
      "Epoch 220/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7523 - val_loss: 0.4962 - val_accuracy: 0.7445\n",
      "Epoch 221/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7529 - val_loss: 0.4962 - val_accuracy: 0.7441\n",
      "Epoch 222/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7523 - val_loss: 0.4962 - val_accuracy: 0.7464\n",
      "Epoch 223/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7524 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 224/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7521 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
      "Epoch 225/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7524 - val_loss: 0.4961 - val_accuracy: 0.7456\n",
      "Epoch 226/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7534 - val_loss: 0.4960 - val_accuracy: 0.7468\n",
      "Epoch 227/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7531 - val_loss: 0.4960 - val_accuracy: 0.7464\n",
      "Epoch 228/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7528 - val_loss: 0.4958 - val_accuracy: 0.7471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7528 - val_loss: 0.4959 - val_accuracy: 0.7475\n",
      "Epoch 230/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7531 - val_loss: 0.4957 - val_accuracy: 0.7468\n",
      "Epoch 231/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7524 - val_loss: 0.4957 - val_accuracy: 0.7452\n",
      "Epoch 232/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7528 - val_loss: 0.4956 - val_accuracy: 0.7471\n",
      "Epoch 233/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7529 - val_loss: 0.4955 - val_accuracy: 0.7468\n",
      "Epoch 234/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7537 - val_loss: 0.4955 - val_accuracy: 0.7475\n",
      "Epoch 235/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7516 - val_loss: 0.4956 - val_accuracy: 0.7479\n",
      "Epoch 236/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7542 - val_loss: 0.4954 - val_accuracy: 0.7471\n",
      "Epoch 237/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7537 - val_loss: 0.4958 - val_accuracy: 0.7487\n",
      "Epoch 238/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7537 - val_loss: 0.4952 - val_accuracy: 0.7479\n",
      "Epoch 239/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7541 - val_loss: 0.4951 - val_accuracy: 0.7479\n",
      "Epoch 240/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7547 - val_loss: 0.4951 - val_accuracy: 0.7468\n",
      "Epoch 241/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7536 - val_loss: 0.4952 - val_accuracy: 0.7471\n",
      "Epoch 242/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7536 - val_loss: 0.4950 - val_accuracy: 0.7471\n",
      "Epoch 243/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7536 - val_loss: 0.4950 - val_accuracy: 0.7464\n",
      "Epoch 244/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7534 - val_loss: 0.4952 - val_accuracy: 0.7483\n",
      "Epoch 245/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7552 - val_loss: 0.4951 - val_accuracy: 0.7479\n",
      "Epoch 246/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7536 - val_loss: 0.4950 - val_accuracy: 0.7490\n",
      "Epoch 247/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7539 - val_loss: 0.4950 - val_accuracy: 0.7490\n",
      "Epoch 248/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7541 - val_loss: 0.4949 - val_accuracy: 0.7471\n",
      "Epoch 249/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7549 - val_loss: 0.4948 - val_accuracy: 0.7475\n",
      "Epoch 250/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7542 - val_loss: 0.4949 - val_accuracy: 0.7487\n",
      "Epoch 251/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7546 - val_loss: 0.4948 - val_accuracy: 0.7487\n",
      "Epoch 252/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7542 - val_loss: 0.4948 - val_accuracy: 0.7487\n",
      "Epoch 253/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7544 - val_loss: 0.4946 - val_accuracy: 0.7475\n",
      "Epoch 254/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7542 - val_loss: 0.4945 - val_accuracy: 0.7487\n",
      "Epoch 255/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7544 - val_loss: 0.4948 - val_accuracy: 0.7456\n",
      "Epoch 256/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7537 - val_loss: 0.4944 - val_accuracy: 0.7475\n",
      "Epoch 257/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7541 - val_loss: 0.4944 - val_accuracy: 0.7490\n",
      "Epoch 258/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7552 - val_loss: 0.4947 - val_accuracy: 0.7479\n",
      "Epoch 259/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7559 - val_loss: 0.4944 - val_accuracy: 0.7471\n",
      "Epoch 260/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7539 - val_loss: 0.4945 - val_accuracy: 0.7490\n",
      "Epoch 261/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7544 - val_loss: 0.4943 - val_accuracy: 0.7494\n",
      "Epoch 262/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7549 - val_loss: 0.4948 - val_accuracy: 0.7487\n",
      "Epoch 263/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7552 - val_loss: 0.4942 - val_accuracy: 0.7483\n",
      "Epoch 264/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7557 - val_loss: 0.4941 - val_accuracy: 0.7483\n",
      "Epoch 265/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7536 - val_loss: 0.4941 - val_accuracy: 0.7490\n",
      "Epoch 266/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7547 - val_loss: 0.4944 - val_accuracy: 0.7487\n",
      "Epoch 267/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7552 - val_loss: 0.4941 - val_accuracy: 0.7471\n",
      "Epoch 268/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7554 - val_loss: 0.4944 - val_accuracy: 0.7483\n",
      "Epoch 269/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7547 - val_loss: 0.4940 - val_accuracy: 0.7490\n",
      "Epoch 270/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7547 - val_loss: 0.4942 - val_accuracy: 0.7479\n",
      "Epoch 271/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7544 - val_loss: 0.4940 - val_accuracy: 0.7498\n",
      "Epoch 272/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7559 - val_loss: 0.4945 - val_accuracy: 0.7487\n",
      "Epoch 273/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7542 - val_loss: 0.4938 - val_accuracy: 0.7498\n",
      "Epoch 274/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7549 - val_loss: 0.4938 - val_accuracy: 0.7498\n",
      "Epoch 275/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7542 - val_loss: 0.4938 - val_accuracy: 0.7502\n",
      "Epoch 276/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7552 - val_loss: 0.4939 - val_accuracy: 0.7494\n",
      "Epoch 277/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7547 - val_loss: 0.4938 - val_accuracy: 0.7517\n",
      "Epoch 278/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7554 - val_loss: 0.4937 - val_accuracy: 0.7490\n",
      "Epoch 279/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7549 - val_loss: 0.4938 - val_accuracy: 0.7498\n",
      "Epoch 280/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7559 - val_loss: 0.4936 - val_accuracy: 0.7502\n",
      "Epoch 281/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7541 - val_loss: 0.4937 - val_accuracy: 0.7475\n",
      "Epoch 282/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7559 - val_loss: 0.4938 - val_accuracy: 0.7487\n",
      "Epoch 283/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7556 - val_loss: 0.4935 - val_accuracy: 0.7510\n",
      "Epoch 284/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7549 - val_loss: 0.4935 - val_accuracy: 0.7502\n",
      "Epoch 285/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7547 - val_loss: 0.4940 - val_accuracy: 0.7490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7552 - val_loss: 0.4935 - val_accuracy: 0.7506\n",
      "Epoch 287/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7559 - val_loss: 0.4934 - val_accuracy: 0.7483\n",
      "Epoch 288/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7559 - val_loss: 0.4935 - val_accuracy: 0.7506\n",
      "Epoch 289/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7551 - val_loss: 0.4935 - val_accuracy: 0.7490\n",
      "Epoch 290/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7552 - val_loss: 0.4936 - val_accuracy: 0.7494\n",
      "Epoch 291/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7551 - val_loss: 0.4935 - val_accuracy: 0.7494\n",
      "Epoch 292/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7559 - val_loss: 0.4933 - val_accuracy: 0.7506\n",
      "Epoch 293/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7565 - val_loss: 0.4933 - val_accuracy: 0.7494\n",
      "Epoch 294/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7549 - val_loss: 0.4932 - val_accuracy: 0.7513\n",
      "Epoch 295/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7557 - val_loss: 0.4933 - val_accuracy: 0.7510\n",
      "Epoch 296/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7564 - val_loss: 0.4933 - val_accuracy: 0.7506\n",
      "Epoch 297/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7554 - val_loss: 0.4932 - val_accuracy: 0.7510\n",
      "Epoch 298/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7564 - val_loss: 0.4934 - val_accuracy: 0.7483\n",
      "Epoch 299/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7556 - val_loss: 0.4933 - val_accuracy: 0.7490\n",
      "Epoch 300/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7549 - val_loss: 0.4929 - val_accuracy: 0.7510\n",
      "Epoch 301/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7562 - val_loss: 0.4936 - val_accuracy: 0.7494\n",
      "Epoch 302/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7554 - val_loss: 0.4933 - val_accuracy: 0.7483\n",
      "Epoch 303/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7557 - val_loss: 0.4933 - val_accuracy: 0.7502\n",
      "Epoch 304/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7564 - val_loss: 0.4930 - val_accuracy: 0.7502\n",
      "Epoch 305/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7559 - val_loss: 0.4930 - val_accuracy: 0.7468\n",
      "Epoch 306/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7554 - val_loss: 0.4931 - val_accuracy: 0.7510\n",
      "Epoch 307/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7569 - val_loss: 0.4930 - val_accuracy: 0.7468\n",
      "Epoch 308/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7554 - val_loss: 0.4928 - val_accuracy: 0.7494\n",
      "Epoch 309/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7565 - val_loss: 0.4932 - val_accuracy: 0.7498\n",
      "Epoch 310/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7554 - val_loss: 0.4928 - val_accuracy: 0.7513\n",
      "Epoch 311/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7569 - val_loss: 0.4928 - val_accuracy: 0.7517\n",
      "Epoch 312/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7567 - val_loss: 0.4925 - val_accuracy: 0.7487\n",
      "Epoch 313/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7547 - val_loss: 0.4928 - val_accuracy: 0.7517\n",
      "Epoch 314/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7565 - val_loss: 0.4931 - val_accuracy: 0.7502\n",
      "Epoch 315/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7557 - val_loss: 0.4926 - val_accuracy: 0.7498\n",
      "Epoch 316/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7565 - val_loss: 0.4927 - val_accuracy: 0.7517\n",
      "Epoch 317/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7564 - val_loss: 0.4925 - val_accuracy: 0.7494\n",
      "Epoch 318/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7565 - val_loss: 0.4927 - val_accuracy: 0.7517\n",
      "Epoch 319/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7560 - val_loss: 0.4924 - val_accuracy: 0.7494\n",
      "Epoch 320/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7570 - val_loss: 0.4925 - val_accuracy: 0.7513\n",
      "Epoch 321/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7582 - val_loss: 0.4923 - val_accuracy: 0.7494\n",
      "Epoch 322/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7554 - val_loss: 0.4924 - val_accuracy: 0.7506\n",
      "Epoch 323/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7574 - val_loss: 0.4923 - val_accuracy: 0.7510\n",
      "Epoch 324/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7570 - val_loss: 0.4921 - val_accuracy: 0.7490\n",
      "Epoch 325/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7570 - val_loss: 0.4924 - val_accuracy: 0.7529\n",
      "Epoch 326/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7565 - val_loss: 0.4922 - val_accuracy: 0.7513\n",
      "Epoch 327/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7579 - val_loss: 0.4932 - val_accuracy: 0.7498\n",
      "Epoch 328/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7562 - val_loss: 0.4927 - val_accuracy: 0.7521\n",
      "Epoch 329/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7577 - val_loss: 0.4921 - val_accuracy: 0.7502\n",
      "Epoch 330/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7577 - val_loss: 0.4919 - val_accuracy: 0.7494\n",
      "Epoch 331/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7574 - val_loss: 0.4920 - val_accuracy: 0.7502\n",
      "Epoch 332/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7579 - val_loss: 0.4934 - val_accuracy: 0.7517\n",
      "Epoch 333/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7585 - val_loss: 0.4922 - val_accuracy: 0.7475\n",
      "Epoch 334/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7572 - val_loss: 0.4920 - val_accuracy: 0.7479\n",
      "Epoch 335/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7582 - val_loss: 0.4919 - val_accuracy: 0.7471\n",
      "Epoch 336/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7572 - val_loss: 0.4923 - val_accuracy: 0.7471\n",
      "Epoch 337/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7592 - val_loss: 0.4920 - val_accuracy: 0.7498\n",
      "Epoch 338/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7569 - val_loss: 0.4920 - val_accuracy: 0.7529\n",
      "Epoch 339/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7569 - val_loss: 0.4917 - val_accuracy: 0.7475\n",
      "Epoch 340/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7582 - val_loss: 0.4919 - val_accuracy: 0.7498\n",
      "Epoch 341/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7580 - val_loss: 0.4918 - val_accuracy: 0.7487\n",
      "Epoch 342/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7569 - val_loss: 0.4918 - val_accuracy: 0.7502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7564 - val_loss: 0.4919 - val_accuracy: 0.7498\n",
      "Epoch 344/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7582 - val_loss: 0.4918 - val_accuracy: 0.7483\n",
      "Epoch 345/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7590 - val_loss: 0.4918 - val_accuracy: 0.7502\n",
      "Epoch 346/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7577 - val_loss: 0.4917 - val_accuracy: 0.7475\n",
      "Epoch 347/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7590 - val_loss: 0.4920 - val_accuracy: 0.7525\n",
      "Epoch 348/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7598 - val_loss: 0.4916 - val_accuracy: 0.7510\n",
      "Epoch 349/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7582 - val_loss: 0.4915 - val_accuracy: 0.7487\n",
      "Epoch 350/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7579 - val_loss: 0.4916 - val_accuracy: 0.7490\n",
      "Epoch 351/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7577 - val_loss: 0.4917 - val_accuracy: 0.7510\n",
      "Epoch 352/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7595 - val_loss: 0.4918 - val_accuracy: 0.7521\n",
      "Epoch 353/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7587 - val_loss: 0.4918 - val_accuracy: 0.7517\n",
      "Epoch 354/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7602 - val_loss: 0.4915 - val_accuracy: 0.7513\n",
      "Epoch 355/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7585 - val_loss: 0.4914 - val_accuracy: 0.7498\n",
      "Epoch 356/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7593 - val_loss: 0.4914 - val_accuracy: 0.7483\n",
      "Epoch 357/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7593 - val_loss: 0.4915 - val_accuracy: 0.7483\n",
      "Epoch 358/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7590 - val_loss: 0.4917 - val_accuracy: 0.7510\n",
      "Epoch 359/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7605 - val_loss: 0.4915 - val_accuracy: 0.7506\n",
      "Epoch 360/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7592 - val_loss: 0.4917 - val_accuracy: 0.7521\n",
      "Epoch 361/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7580 - val_loss: 0.4916 - val_accuracy: 0.7510\n",
      "Epoch 362/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7593 - val_loss: 0.4919 - val_accuracy: 0.7513\n",
      "Epoch 363/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7592 - val_loss: 0.4917 - val_accuracy: 0.7498\n",
      "Epoch 364/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7595 - val_loss: 0.4912 - val_accuracy: 0.7510\n",
      "Epoch 365/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7592 - val_loss: 0.4914 - val_accuracy: 0.7506\n",
      "Epoch 366/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7577 - val_loss: 0.4912 - val_accuracy: 0.7510\n",
      "Epoch 367/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7587 - val_loss: 0.4916 - val_accuracy: 0.7498\n",
      "Epoch 368/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7590 - val_loss: 0.4912 - val_accuracy: 0.7498\n",
      "Epoch 369/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7600 - val_loss: 0.4911 - val_accuracy: 0.7498\n",
      "Epoch 370/1000\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7592 - val_loss: 0.4913 - val_accuracy: 0.7506\n",
      "Epoch 371/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7602 - val_loss: 0.4911 - val_accuracy: 0.7494\n",
      "Epoch 372/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7595 - val_loss: 0.4913 - val_accuracy: 0.7506\n",
      "Epoch 373/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7587 - val_loss: 0.4912 - val_accuracy: 0.7506\n",
      "Epoch 374/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7603 - val_loss: 0.4910 - val_accuracy: 0.7498\n",
      "Epoch 375/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7613 - val_loss: 0.4915 - val_accuracy: 0.7510\n",
      "Epoch 376/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7598 - val_loss: 0.4912 - val_accuracy: 0.7521\n",
      "Epoch 377/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7602 - val_loss: 0.4909 - val_accuracy: 0.7490\n",
      "Epoch 378/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7593 - val_loss: 0.4908 - val_accuracy: 0.7487\n",
      "Epoch 379/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7590 - val_loss: 0.4918 - val_accuracy: 0.7510\n",
      "Epoch 380/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7598 - val_loss: 0.4909 - val_accuracy: 0.7502\n",
      "Epoch 381/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7590 - val_loss: 0.4917 - val_accuracy: 0.7502\n",
      "Epoch 382/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7585 - val_loss: 0.4909 - val_accuracy: 0.7517\n",
      "Epoch 383/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7600 - val_loss: 0.4909 - val_accuracy: 0.7494\n",
      "Epoch 384/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7598 - val_loss: 0.4909 - val_accuracy: 0.7513\n",
      "Epoch 385/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7585 - val_loss: 0.4910 - val_accuracy: 0.7510\n",
      "Epoch 386/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7600 - val_loss: 0.4910 - val_accuracy: 0.7513\n",
      "Epoch 387/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7607 - val_loss: 0.4910 - val_accuracy: 0.7468\n",
      "Epoch 388/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7607 - val_loss: 0.4910 - val_accuracy: 0.7498\n",
      "Epoch 389/1000\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7593 - val_loss: 0.4913 - val_accuracy: 0.7502\n",
      "Epoch 390/1000\n",
      " 1/48 [..............................] - ETA: 0s - loss: 0.4167 - accuracy: 0.8281"
     ]
    }
   ],
   "source": [
    "epoch_size = 1000\n",
    "batch_size = 128\n",
    "history = model.fit(train_data.drop(columns=target), train_data[target], \n",
    "                    epochs = epoch_size, batch_size=batch_size,\n",
    "                    validation_data=(test_data.drop(columns=target), test_data[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame()\n",
    "\n",
    "history_df['epoch_round'] = [num+1 for num in range(epoch_size)]\n",
    "history_df['training_loss'] = history.history['loss']\n",
    "history_df['training_accuracy'] = history.history['accuracy']\n",
    "history_df['val_loss'] = history.history['val_loss']\n",
    "history_df['val_accuracy'] = history.history['val_accuracy']\n",
    "\n",
    "# helps get rid of the initial outliers for visuals\n",
    "history_df = history_df.loc[history_df['epoch_round']>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac0ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.grid(True)\n",
    "\n",
    "plt.plot(history_df['epoch_round'], history_df['training_loss'], marker='o',\n",
    "        linestyle='-', color='blue', label='training_loss')\n",
    "plt.plot(history_df['epoch_round'], history_df['val_loss'], marker='o',\n",
    "        linestyle='-', color='green', label='val_loss')\n",
    "\n",
    "plt.xlabel('epoch_round')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Loss visualized')\n",
    "\n",
    "legend = plt.legend()\n",
    "\n",
    "# Set the legend text color to white\n",
    "for text in legend.get_texts():\n",
    "    text.set_color('black')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.grid(True)\n",
    "\n",
    "plt.plot(history_df['epoch_round'], history_df['training_accuracy'], marker='o',\n",
    "        linestyle='-', color='blue', label='training_accuracy')\n",
    "plt.plot(history_df['epoch_round'], history_df['val_accuracy'], marker='o',\n",
    "        linestyle='-', color='green', label='val_accuracy')\n",
    "\n",
    "plt.xlabel('epoch_round')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy visualized')\n",
    "\n",
    "legend = plt.legend()\n",
    "\n",
    "# Set the legend text color to white\n",
    "for text in legend.get_texts():\n",
    "    text.set_color('black')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5088439e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95131002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e93f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
